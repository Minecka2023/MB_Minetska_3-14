{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPHtHSXHN0U42L0r5fhKz2S",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Minecka2023/MB_Minetska_3-14/blob/main/LB11_MB_Minetska_3_14.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aqCCo51tXU6e",
        "outputId": "0e710b1a-816d-4fae-d061-83455732b410"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "60000 train samples\n",
            "10000 test samples\n",
            "image shape (28, 28)\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_2 (Conv2D)           (None, 26, 26, 32)        320       \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 24, 24, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPoolin  (None, 12, 12, 64)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 12, 12, 64)        0         \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 9216)              0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 128)               1179776   \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1199882 (4.58 MB)\n",
            "Trainable params: 1199882 (4.58 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/12\n",
            "  5/469 [..............................] - ETA: 2:02 - loss: 2.0866 - accuracy: 0.3203"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.datasets import mnist\n",
        "num_classes = 10\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n",
        "print('image shape', x_train[0].shape)\n",
        "batch_size = 128\n",
        "num_classes = 10\n",
        "epochs = 12\n",
        "\n",
        "# input image dimensions\n",
        "img_rows, img_cols = 28, 28\n",
        "input_dim = img_rows * img_cols\n",
        "\n",
        "x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
        "x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
        "input_shape = (img_rows, img_cols, 1)\n",
        "\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "\n",
        "# convert class vectors to binary class matrices\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "model =  keras.Sequential()\n",
        "model.add(layers.Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=input_shape))\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(layers.Dropout(0.25))\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(128, activation='relu'))\n",
        "model.add(layers.Dropout(0.5))\n",
        "model.add(layers.Dense(num_classes, activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.summary()\n",
        "model.fit(x_train, y_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          verbose=1,\n",
        "          validation_data=(x_test, y_test))\n",
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "import matplotlib.pyplot as plt\n",
        "(train_features, train_labels), (test_features, test_labels) = cifar10.load_data()\n",
        "print(train_features.shape)\n",
        "print(test_features.shape)\n",
        "train_features = train_features.astype('float32')/255\n",
        "test_features = test_features.astype('float32')/255\n",
        "num_classes = 10\n",
        "train_labels = keras.utils.to_categorical(train_labels, num_classes)\n",
        "test_labels = keras.utils.to_categorical(test_labels, num_classes)\n",
        "n = 10\n",
        "plt.figure(figsize=(20, 4))\n",
        "for i in range(n):\n",
        "\n",
        "    ax = plt.subplot(2, n, i + 1)\n",
        "    plt.imshow(train_features[i])\n",
        "    plt.gray()\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "CP50_S32XhLJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "alpha = 0.02\n",
        "\n",
        "model = keras.Sequential()\n",
        "\n",
        "model.add(layers.Conv2D(filters=16, kernel_size=(3, 3), padding=\"same\", input_shape=(train_features.shape[1:])))\n",
        "model.add(layers.LeakyReLU(alpha=alpha))\n",
        "model.add(layers.MaxPooling2D(pool_size=(2, 2), padding='same'))\n",
        "\n",
        "model.add(layers.Conv2D(filters=32, kernel_size=(3, 3), padding=\"same\"))\n",
        "model.add(layers.LeakyReLU(alpha=alpha))\n",
        "model.add(layers.MaxPooling2D(pool_size=(2, 2), padding='same'))\n",
        "\n",
        "model.add(layers.Conv2D(filters=64, kernel_size=(3, 3), padding=\"same\"))\n",
        "model.add(layers.LeakyReLU(alpha=alpha))\n",
        "model.add(layers.MaxPooling2D(pool_size=(2, 2), padding='same'))\n",
        "\n",
        "model.add(layers.Flatten())\n",
        "\n",
        "model.add(layers.Dense(512))\n",
        "model.add(layers.LeakyReLU(alpha=alpha))\n",
        "\n",
        "model.add(layers.Dense(10, activation=\"softmax\"))\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "model.summary()\n"
      ],
      "metadata": {
        "id": "qIRRghfzXh2I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "my_callbacks = [tf.keras.callbacks.EarlyStopping(patience=5)]\n",
        "\n",
        "model.fit(train_features, train_labels, validation_split=0.2, epochs=5, batch_size=128, callbacks = my_callbacks, verbose=1)"
      ],
      "metadata": {
        "id": "1YH3KvO2XkI5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "score = model.evaluate(test_features, test_labels, verbose=0)\n",
        "print('Test score:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "metadata": {
        "id": "0-lj7OSoXmNU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import imdb\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Embedding, Conv1D, GlobalMaxPooling1D\n",
        "\n",
        "# Завантаження даних\n",
        "num_words = 10000  # обмеження числа слів у відгуку\n",
        "maxlen = 200  # максимальна довжина відгуку\n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=num_words)\n",
        "\n",
        "# Попередня обробка даних\n",
        "x_train = pad_sequences(x_train, maxlen=maxlen)\n",
        "x_test = pad_sequences(x_test, maxlen=maxlen)\n",
        "\n",
        "# Побудова моделі\n",
        "model = Sequential()\n",
        "model.add(Embedding(num_words, 128, input_length=maxlen))\n",
        "model.add(Conv1D(128, 5, activation='relu'))\n",
        "model.add(GlobalMaxPooling1D())\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Компіляція моделі\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Навчання моделі\n",
        "batch_size = 32\n",
        "epochs = 5\n",
        "model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_data=(x_test, y_test))\n",
        "\n",
        "# Оцінка моделі\n",
        "loss, accuracy = model.evaluate(x_test, y_test)\n",
        "print(\"Test Accuracy:\", accuracy)\n"
      ],
      "metadata": {
        "id": "LCz_l464XoiJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Завантаження даних\n",
        "train_df = pd.read_csv('fashion-mnist_train.csv')\n",
        "test_df = pd.read_csv('fashion-mnist_test.csv')\n",
        "\n",
        "# Виділення функцій та міток\n",
        "X_train = train_df.drop('label', axis=1).values.reshape(train_df.shape[0], 28, 28, 1).astype('float32') / 255.0\n",
        "y_train = to_categorical(train_df['label'].values)\n",
        "\n",
        "X_test = test_df.drop('label', axis=1).values.reshape(test_df.shape[0], 28, 28, 1).astype('float32') / 255.0\n",
        "y_test = to_categorical(test_df['label'].values)\n",
        "\n",
        "# Розбиття тренувальних даних для створення валідаційного набору\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
        "\n",
        "# Побудова моделі CNN\n",
        "model = Sequential([\n",
        "    Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
        "    MaxPooling2D(2, 2),\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    MaxPooling2D(2, 2),\n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(10, activation='softmax')  # 10 класів у Fashion MNIST\n",
        "])\n",
        "\n",
        "# Компіляція моделі\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Тренування моделі\n",
        "history = model.fit(X_train, y_train, batch_size=64, epochs=10, validation_data=(X_val, y_val))\n",
        "\n",
        "# Оцінка моделі на тестових даних\n",
        "test_loss, test_acc = model.evaluate(X_test, y_test, verbose=2)\n",
        "print('\\nTest accuracy:', test_acc)\n",
        "\n",
        "model.summary()\n"
      ],
      "metadata": {
        "id": "r62v2Sj5XqDB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}